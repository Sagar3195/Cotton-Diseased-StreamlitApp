# -*- coding: utf-8 -*-
"""Deployment of Cotton_Leaf_Disease model on Streamlit.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VN9BlvJFIy0nyjzSVp4VW_8AItn7D8Vu
"""

!pip install streamlit

!pip install pyngrok==4.1.1

!pip install tensorflow-gpu

# Commented out IPython magic to ensure Python compatibility.
# %%writefile cotton.py
# import streamlit as st
# import tensorflow as tf
#    
# 
# st.set_option('deprecation.showfileUploaderEncoding', False)
# @st.cache(allow_output_mutation = True)
# 
# def load_model():
#   model = tf.keras.models.load_model("/content/drive/MyDrive/Cotton_disease/cotton_disease_model_inception.h5")
#   return model
# 
# model = load_model()
# st.write("## Cotton Leaf Disease Classification")
# 
# file = st.file_uploader("Please upload an cotton leaf image", type = ['jpg', 'png'])
# import cv2
# from PIL import Image, ImageOps
# import numpy as np
# 
# def import_and_predict(image_data, model):
#   size = (224, 224)
#   image = ImageOps.fit(image_data, size, Image.ANTIALIAS) 
#   img = np.asarray(image) 
#   img = img/255.0 
#   img_reshape = img[np.newaxis,...]
#   prediction= model.predict(img_reshape)
# 
#   return prediction
# 
# 
# if file is None:
#   st.text("Please upload an image file")
# else:
#   image = Image.open(file)
#   st.image(image, use_column_width = True)
#   predictions = import_and_predict(image, model) 
#   class_names = ['diseased cotton leaf', 'diseased cotton plant', 'fresh cotton leaf', 'fresh cotton plant']
#   string = "It is {}".format(class_names[np.argmax(predictions)])
#   st.success(string)
# 
#



#!ngrok authtoken XXXXXXXXXXXXXXXXXXXXXXXXXXXX



!nohup streamlit run cotton.py &

from pyngrok import ngrok
public_url = ngrok.connect(port = '8501')
public_url

!cat /content/nohup.out

#ngrok.kill()
